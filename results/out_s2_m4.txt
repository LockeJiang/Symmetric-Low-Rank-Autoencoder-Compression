Using CUDA!
AE(
  (encoder_l1): MaskedLinear(in_features=784, out_features=64, bias=True)
  (encoder_l2): MaskedLinear(in_features=64, out_features=32, bias=True)
  (encoder_l3): MaskedLinear(in_features=32, out_features=100, bias=True)
  (decoder_l1): MaskedLinear(in_features=10, out_features=32, bias=True)
  (decoder_l2): MaskedLinear(in_features=32, out_features=64, bias=True)
  (decoder_l3): MaskedLinear(in_features=64, out_features=784, bias=True)
)
Param name           Shape                          Type           
----------------------------------------------------------------------
encoder_l1.weight    torch.Size([64, 784])          torch.float32  
encoder_l1.mask      torch.Size([64, 784])          torch.float32  
encoder_l1.bias      torch.Size([64])               torch.float32  
encoder_l2.weight    torch.Size([32, 64])           torch.float32  
encoder_l2.mask      torch.Size([32, 64])           torch.float32  
encoder_l2.bias      torch.Size([32])               torch.float32  
encoder_l3.weight    torch.Size([100, 32])          torch.float32  
encoder_l3.mask      torch.Size([100, 32])          torch.float32  
encoder_l3.bias      torch.Size([100])              torch.float32  
decoder_l1.weight    torch.Size([32, 10])           torch.float32  
decoder_l1.mask      torch.Size([32, 10])           torch.float32  
decoder_l1.bias      torch.Size([32])               torch.float32  
decoder_l2.weight    torch.Size([64, 32])           torch.float32  
decoder_l2.mask      torch.Size([64, 32])           torch.float32  
decoder_l2.bias      torch.Size([64])               torch.float32  
decoder_l3.weight    torch.Size([784, 64])          torch.float32  
decoder_l3.mask      torch.Size([784, 64])          torch.float32  
decoder_l3.bias      torch.Size([784])              torch.float32  
--- Initial training ---
accuracy before weight sharing
invoking test_vae
10000
Test set: Average loss: 2.4943
accuacy after weight sharing
invoking test_vae
10000
Test set: Average loss: 2.7936
Layer           |   original compressed improvement percent
----------------------------------------------------------------------
encoder_l1.weight |     154924      32049       4.83x  20.69%
encoder_l1.bias |       6148       2768       2.22x  45.02%
encoder_l2.weight |      58924      13576       4.34x  23.04%
encoder_l2.bias |       3076       1360       2.26x  44.21%
encoder_l3.weight |      16748       4509       3.71x  26.92%
encoder_l3.bias |       1540        672       2.29x  43.64%
decoder_l1.weight |      16220       4343       3.73x  26.78%
decoder_l1.bias |       3076       1360       2.26x  44.21%
decoder_l2.weight |      56364      12777       4.41x  22.67%
decoder_l2.bias |       6148       2768       2.22x  45.02%
decoder_l3.weight |     151052      30512       4.95x  20.20%
decoder_l3.bias |       9412       3511       2.68x  37.30%
----------------------------------------------------------------------
total           |     483632     110205       4.39x  22.79%
Using CUDA!
AE(
  (encoder_l1): MaskedLinear(in_features=784, out_features=64, bias=True)
  (encoder_l2): MaskedLinear(in_features=64, out_features=32, bias=True)
  (encoder_l3): MaskedLinear(in_features=32, out_features=10, bias=True)
  (decoder_l1): MaskedLinear(in_features=10, out_features=32, bias=True)
  (decoder_l2): MaskedLinear(in_features=32, out_features=64, bias=True)
  (decoder_l3): MaskedLinear(in_features=64, out_features=784, bias=True)
)
Param name           Shape                          Type           
----------------------------------------------------------------------
encoder_l1.weight    torch.Size([64, 784])          torch.float32  
encoder_l1.mask      torch.Size([64, 784])          torch.float32  
encoder_l1.bias      torch.Size([64])               torch.float32  
encoder_l2.weight    torch.Size([32, 64])           torch.float32  
encoder_l2.mask      torch.Size([32, 64])           torch.float32  
encoder_l2.bias      torch.Size([32])               torch.float32  
encoder_l3.weight    torch.Size([10, 32])           torch.float32  
encoder_l3.mask      torch.Size([10, 32])           torch.float32  
encoder_l3.bias      torch.Size([10])               torch.float32  
decoder_l1.weight    torch.Size([32, 10])           torch.float32  
decoder_l1.mask      torch.Size([32, 10])           torch.float32  
decoder_l1.bias      torch.Size([32])               torch.float32  
decoder_l2.weight    torch.Size([64, 32])           torch.float32  
decoder_l2.mask      torch.Size([64, 32])           torch.float32  
decoder_l2.bias      torch.Size([64])               torch.float32  
decoder_l3.weight    torch.Size([784, 64])          torch.float32  
decoder_l3.mask      torch.Size([784, 64])          torch.float32  
decoder_l3.bias      torch.Size([784])              torch.float32  
--- Initial training ---
invoking test_vae
Test set: Average loss: 3.9717
--- Before pruning ---
encoder_l1.weight    | nonzeros =   50176 /   50176 (100.00%) | total_pruned =       0 | shape = (64, 784)
encoder_l1.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
encoder_l2.weight    | nonzeros =    2048 /    2048 (100.00%) | total_pruned =       0 | shape = (32, 64)
encoder_l2.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
encoder_l3.weight    | nonzeros =     320 /     320 (100.00%) | total_pruned =       0 | shape = (10, 32)
encoder_l3.bias      | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)
decoder_l1.weight    | nonzeros =     320 /     320 (100.00%) | total_pruned =       0 | shape = (32, 10)
decoder_l1.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
decoder_l2.weight    | nonzeros =    2048 /    2048 (100.00%) | total_pruned =       0 | shape = (64, 32)
decoder_l2.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
decoder_l3.weight    | nonzeros =   50176 /   50176 (100.00%) | total_pruned =       0 | shape = (784, 64)
decoder_l3.bias      | nonzeros =     784 /     784 (100.00%) | total_pruned =       0 | shape = (784,)
alive: 106074, pruned : 0, total: 106074, Compression rate :       1.00x  (  0.00% pruned)
Pruning with threshold : 0.062038153409957886 for layer encoder_l1
Pruning with threshold : 0.25621408224105835 for layer encoder_l2
Pruning with threshold : 0.3760969042778015 for layer encoder_l3
Pruning with threshold : 0.3721071481704712 for layer decoder_l1
Pruning with threshold : 0.2350476086139679 for layer decoder_l2
Pruning with threshold : 0.07625027000904083 for layer decoder_l3
invoking test_vae
Test set: Average loss: 10.1187
--- After pruning ---
encoder_l1.weight    | nonzeros =    3054 /   50176 (  6.09%) | total_pruned =   47122 | shape = (64, 784)
encoder_l1.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
encoder_l2.weight    | nonzeros =     155 /    2048 (  7.57%) | total_pruned =    1893 | shape = (32, 64)
encoder_l2.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
encoder_l3.weight    | nonzeros =      18 /     320 (  5.62%) | total_pruned =     302 | shape = (10, 32)
encoder_l3.bias      | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)
decoder_l1.weight    | nonzeros =      23 /     320 (  7.19%) | total_pruned =     297 | shape = (32, 10)
decoder_l1.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
decoder_l2.weight    | nonzeros =      97 /    2048 (  4.74%) | total_pruned =    1951 | shape = (64, 32)
decoder_l2.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
decoder_l3.weight    | nonzeros =    3384 /   50176 (  6.74%) | total_pruned =   46792 | shape = (784, 64)
decoder_l3.bias      | nonzeros =     784 /     784 (100.00%) | total_pruned =       0 | shape = (784,)
alive: 7717, pruned : 98357, total: 106074, Compression rate :      13.75x  ( 92.72% pruned)
--- Retraining ---
invoking test_vae
Test set: Average loss: 5.4750
--- After Retraining ---
encoder_l1.weight    | nonzeros =    3054 /   50176 (  6.09%) | total_pruned =   47122 | shape = (64, 784)
encoder_l1.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
encoder_l2.weight    | nonzeros =     155 /    2048 (  7.57%) | total_pruned =    1893 | shape = (32, 64)
encoder_l2.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
encoder_l3.weight    | nonzeros =      18 /     320 (  5.62%) | total_pruned =     302 | shape = (10, 32)
encoder_l3.bias      | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)
decoder_l1.weight    | nonzeros =      23 /     320 (  7.19%) | total_pruned =     297 | shape = (32, 10)
decoder_l1.bias      | nonzeros =      32 /      32 (100.00%) | total_pruned =       0 | shape = (32,)
decoder_l2.weight    | nonzeros =      97 /    2048 (  4.74%) | total_pruned =    1951 | shape = (64, 32)
decoder_l2.bias      | nonzeros =      64 /      64 (100.00%) | total_pruned =       0 | shape = (64,)
decoder_l3.weight    | nonzeros =    3384 /   50176 (  6.74%) | total_pruned =   46792 | shape = (784, 64)
decoder_l3.bias      | nonzeros =     784 /     784 (100.00%) | total_pruned =       0 | shape = (784,)
alive: 7717, pruned : 98357, total: 106074, Compression rate :      13.75x  ( 92.72% pruned)
accuracy before weight sharing
invoking test_vae
10000
Test set: Average loss: 5.4750
Layer           |   original compressed improvement percent
----------------------------------------------------------------------
encoder_l1.weight |     154924      32049       4.83x  20.69%
encoder_l1.bias |       6148       2768       2.22x  45.02%
encoder_l2.weight |      58924      13576       4.34x  23.04%
encoder_l2.bias |       3076       1360       2.26x  44.21%
encoder_l3.weight |      16748       4509       3.71x  26.92%
encoder_l3.bias |       1540        672       2.29x  43.64%
decoder_l1.weight |      16220       4343       3.73x  26.78%
decoder_l1.bias |       3076       1360       2.26x  44.21%
decoder_l2.weight |      56364      12777       4.41x  22.67%
decoder_l2.bias |       6148       2768       2.22x  45.02%
decoder_l3.weight |     151052      30512       4.95x  20.20%
decoder_l3.bias |       9412       3511       2.68x  37.30%
----------------------------------------------------------------------
total           |     483632     110205       4.39x  22.79%
